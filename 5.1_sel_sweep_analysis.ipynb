{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84ca86-4c2f-4c95-8777-859abb99ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute classical population genetic neutrality statistics (Tajima's D, Fu & Li's D, \n",
    "Fay & Wu's H, Zeng's E) in sliding windows from SLiM simulation outputs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nrand\n",
    "import scipy.stats as stats\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc77839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define helper functions for harmonic-number–based constants and each neutrality statistic.\n",
    "\"\"\"\n",
    "\n",
    "def scaling_factor(n):\n",
    "    \"\"\"\n",
    "    Compute a1 = sum_{i=1}^{n-1} 1/i.\n",
    "    \"\"\"\n",
    "    a = 0\n",
    "    if n == 20000: #  return precomputed value for large n to save time.\n",
    "        return 10.48067821722932 \n",
    "    for i in range(1, n):\n",
    "        a += 1/i\n",
    "    return a\n",
    "\n",
    "def get_a2(n):\n",
    "    \"\"\"\n",
    "    Compute a2 = sum_{i=1}^{n-1} 1/i^2.\n",
    "    \"\"\"\n",
    "    a = 0\n",
    "    if n == 20000: #  return precomputed value for large n to save time.\n",
    "        return 1.6448840655982087\n",
    "    elif n == 20001:\n",
    "        return 1.6448840680982086\n",
    "    for i in range(1, n):\n",
    "        a += 1/(i**2)\n",
    "    return a\n",
    "\n",
    "def get_TajimasD(mut_df, Ne):\n",
    "    n = 2*Ne\n",
    "    a1 = scaling_factor(n)\n",
    "    a2 = get_a2(n)\n",
    "    b1 = (n+1)/(3*(n-1))\n",
    "    b2 = 2*(n**2+n+3)/(9*n*(n-1))\n",
    "    c1 = b1-1/a1\n",
    "    c2 = b2-(n+2)/(a1*n)+a2/(a1**2)\n",
    "    e1 = c1/a1\n",
    "    e2 = c2/(a1**2+a2)\n",
    "    AF = mut_df['AF']/(2*Ne)\n",
    "    Tpi = 2*AF*(1-AF)\n",
    "    Tpi_sum = np.sum(Tpi)\n",
    "    S = len(mut_df)\n",
    "    TW = S/scaling_factor(2*Ne)\n",
    "    D = (Tpi_sum - TW)/np.sqrt(e1*S+e2*S*(S-1))\n",
    "    return D\n",
    "\n",
    "def get_FuLisD(mut_df, Ne):\n",
    "    n = 2*Ne\n",
    "    S = len(mut_df)\n",
    "    Se = (mut_df['AF'] == 1).sum()\n",
    "    an = scaling_factor(n)\n",
    "    bn = get_a2(n)\n",
    "    cn = 2*(n*an-2*(n-1))/(n-1)/(n-2)\n",
    "    vd = 1+an**2/(bn+an**2)*(cn-(n+1)/(n-1))\n",
    "    ud = an - 1 - vd\n",
    "    D = (S - an*Se)/np.sqrt(ud*S+vd*S**2)\n",
    "    return D\n",
    "\n",
    "def get_FayWusH(mut_df, Ne):\n",
    "    n = 2*Ne\n",
    "    TL = mut_df['AF'].sum()/(n-1)\n",
    "    AF = mut_df['AF']/n\n",
    "    Tpi = 2*AF*(1-AF)\n",
    "    Tpi_sum = np.sum(Tpi)\n",
    "    S = len(mut_df)\n",
    "    an = scaling_factor(n)\n",
    "    bn = get_a2(n)\n",
    "    bn_1 = get_a2(n+1)\n",
    "    T = S/an\n",
    "    T2 = S*(S-1)/(an**2+bn)\n",
    "    var = T*(n-2)/(6*(n-1)) + T2*(18*n**2*(3*n+2)*bn_1-(88*n**3+9*n**2-13*n+6))/(9*n*(n-1)**2)\n",
    "    H = (Tpi_sum - TL)/np.sqrt(var)\n",
    "    return H\n",
    "\n",
    "def get_ZengsE(mut_df, Ne):\n",
    "    n = 2*Ne\n",
    "    an = scaling_factor(n)\n",
    "    bn = get_a2(n)\n",
    "    S = len(mut_df)\n",
    "    TL = mut_df['AF'].sum()/(2*Ne-1)\n",
    "    TW = S/an\n",
    "    T2 = S*(S-1)/(an**2+bn)\n",
    "    var = TW*(n/(2*(n-1))-1/an) + T2*(bn/an**2+2*bn*(n/(n-1))**2-2*(n*bn-n+1)/(an*(n-1))-(3*n+1)/(n-1))\n",
    "    E = (TL - TW)/np.sqrt(var)\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929af8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For each simulation model (\"version\") and replicate:\n",
    "   - Load mutation data from text files (allele frequencies, positions, etc.).\n",
    "   - Slide a window (10kb wide, shifted 1kb each step) across the genome.\n",
    "   - Compute statistics for each window and collect them.\n",
    "\n",
    "Inputs\n",
    "------\n",
    "./data/Simulation_selsweep/rep<rep>/<version>_20samples/<version>_<N_gen>.txt\n",
    "    Text tables from simulations. Must include:\n",
    "    - ID  (mutation identifier)\n",
    "    - pos (genomic position)\n",
    "    - s   (selection coefficient)\n",
    "    - SG  (generation when mutation arose)\n",
    "    - AF  (allele frequency in counts, not normalized)\n",
    "\"\"\"\n",
    "\n",
    "# Parameters for windowed analysis\n",
    "sliding_size = 1000\n",
    "window_size = 10000\n",
    "Ne = 10000\n",
    "\n",
    "# Containers for results\n",
    "TajimasD_dict = {}\n",
    "FuLisD_dict = {}\n",
    "FayWusH_dict = {}\n",
    "ZengsE_dict = {}\n",
    "\n",
    "# Iterate over models and replicates\n",
    "for version in ['Pseudo', 'Neutral', 'AdapTrack', 'AdapTrack_env20', 'Adaptive']:\n",
    "    print(version)\n",
    "    TajimasD_list = []\n",
    "    FuLisD_list = []\n",
    "    FayWusH_list = []\n",
    "    ZengsE_list = []\n",
    "    for rep in range(1, 31):\n",
    "        print(rep, end='\\r', flush=True)\n",
    "        target_dir = \\\n",
    "            f'./data/Simulation_selsweep/rep{rep}/{version}_20samples/'   \n",
    "        for N_gen in range(80000, 100001, 1000): # generations 80k–100k, step 1k\n",
    "            print(N_gen, end='\\r', flush=True)\n",
    "            mut_df = pd.read_table(target_dir+f'{version}_{N_gen}.txt', header=None, sep='\\s+')\n",
    "            \n",
    "            # keep only relevant columns\n",
    "            mut_df = mut_df.rename(columns={4:'ID', 6:'pos', 7:'s', 10:'SG', 11:'AF'})\n",
    "\n",
    "            # Slide windows across genome (100 kb total length assumed from code)\n",
    "            for i in range(int((100000-window_size)/sliding_size)+1):\n",
    "                mut_df_sub = mut_df[\n",
    "                    (i*sliding_size<mut_df['pos']) & (mut_df['pos'] < i*sliding_size+window_size)\n",
    "                ]\n",
    "\n",
    "                # Compute statistics on this window\n",
    "                TajimasD = get_TajimasD(mut_df_sub, Ne)\n",
    "                FuLisD = get_FuLisD(mut_df_sub, Ne)\n",
    "                FayWusH = get_FayWusH(mut_df_sub, Ne)\n",
    "                ZengsE = get_ZengsE(mut_df_sub, Ne)\n",
    "                TajimasD_list.append(TajimasD)\n",
    "                FuLisD_list.append(FuLisD)\n",
    "                FayWusH_list.append(FayWusH)\n",
    "                ZengsE_list.append(ZengsE)\n",
    "    \n",
    "    # Store results\n",
    "    TajimasD_dict[version] = TajimasD_list\n",
    "    FuLisD_dict[version] = FuLisD_list\n",
    "    FayWusH_dict[version] = FayWusH_list\n",
    "    ZengsE_dict[version] = ZengsE_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to overwrite result files\n",
    "\n",
    "# with open('./data/TajimasD_dict.pkl', 'wb') as f:\n",
    "#     pkl.dump(TajimasD_dict, f)\n",
    "# with open('./data/FuLisD_dict.pkl', 'wb') as f:\n",
    "#     pkl.dump(FuLisD_dict, f)\n",
    "# with open('./data/FayWusH_dict.pkl', 'wb') as f:\n",
    "#     pkl.dump(FayWusH_dict, f)\n",
    "# with open('./data/ZengsE_dict.pkl', 'wb') as f:\n",
    "#     pkl.dump(ZengsE_dict, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
